HEALTHCARE ANALYTICS LAB - QUERY ANALYSIS
OLTP Schema Performance Evaluation
==========================================

QUESTION 1: Monthly Encounters by Specialty
--------------------------------------------

SQL Query:
SELECT 
    DATE_FORMAT(e.encounter_date, '%Y-%m') AS encounter_month,
    s.specialty_name,
    e.encounter_type,
    COUNT(DISTINCT e.encounter_id) AS total_encounters,
    COUNT(DISTINCT e.patient_id) AS unique_patients
FROM encounters e
INNER JOIN providers p ON e.provider_id = p.provider_id
INNER JOIN specialties s ON p.specialty_id = s.specialty_id
GROUP BY 
    DATE_FORMAT(e.encounter_date, '%Y-%m'),
    s.specialty_name,
    e.encounter_type
ORDER BY 
    encounter_month,
    s.specialty_name,
    e.encounter_type;

Schema Analysis:
- Tables joined: 3 (encounters → providers → specialties)
- Number of joins: 2

Performance (13.2k Rows):
- Execution time: 0.174 seconds (174 milliseconds) 
- Estimated rows scanned: ~13,233 rows
- Actual rows processed: 13,200 rows from encounters table

Bottleneck Identified:
- Full sort operation: 13,200 rows sorted before grouping.
- Nested loop joins: Higher volume of loops (1000 providers x ~13.2 avg encounters).
- Date calculation at query time: `DATE_FORMAT()` computed 13,200 times.
- Scaling Issue: Latency tripled (52ms -> 174ms) with only 30% more data.

==========================================

QUESTION 2: Top Diagnosis-Procedure Pairs
------------------------------------------

SQL Query:
SELECT 
    d.icd10_code,
    d.icd10_description,
    pr.cpt_code,
    pr.cpt_description,
    COUNT(DISTINCT ed.encounter_id) AS encounter_count
FROM encounter_diagnoses ed
INNER JOIN diagnoses d ON ed.diagnosis_id = d.diagnosis_id
INNER JOIN encounter_procedures ep ON ed.encounter_id = ep.encounter_id
INNER JOIN procedures pr ON ep.procedure_id = pr.procedure_id
GROUP BY 
    d.icd10_code,
    d.icd10_description,
    pr.cpt_code,
    pr.cpt_description
ORDER BY 
    encounter_count DESC;

Schema Analysis:
- Tables joined: 4 (encounter_diagnoses → diagnoses → encounter_procedures → procedures)
- Number of joins: 4

Performance (13.2k Rows):
- Execution time: 0.174 seconds (174 milliseconds) 
- Estimated rows scanned: ~13,317 rows
- Actual rows processed: 13,200 rows from diagnoses/junction tables

Bottleneck Identified:
- Full table scan: Initial scan grew to 13,200 rows.
- Cartesian complexity: Junction joins create larger intermediate sets (~13.2k rows).
- Double sort: Sorting 13.2k rows before Group By and 592 rows after.
- Scaling Issue: Complexity of many-to-many joins scales poorly with volume.

==========================================

QUESTION 3: 30-Day Readmission Rate
------------------------------------

SQL Query:
WITH inpatient_discharges AS (
    SELECT 
        e1.patient_id,
        e1.encounter_id AS initial_encounter_id,
        e1.discharge_date,
        e1.provider_id,
        p.specialty_id
    FROM encounters e1
    INNER JOIN providers p ON e1.provider_id = p.provider_id
    WHERE e1.encounter_type = 'Inpatient' 
      AND e1.discharge_date IS NOT NULL
),
readmissions AS (
    SELECT 
        id.patient_id,
        id.initial_encounter_id,
        id.discharge_date,
        id.specialty_id,
        e2.encounter_id AS readmission_encounter_id,
        e2.encounter_date AS readmission_date,
        DATEDIFF(e2.encounter_date, id.discharge_date) AS days_to_readmit
    FROM inpatient_discharges id
    INNER JOIN encounters e2 
        ON id.patient_id = e2.patient_id
        AND e2.encounter_type = 'Inpatient'
        AND e2.encounter_date > id.discharge_date
        AND DATEDIFF(e2.encounter_date, id.discharge_date) <= 30
)
SELECT 
    s.specialty_name,
    COUNT(DISTINCT id.initial_encounter_id) AS total_discharges,
    COUNT(DISTINCT r.readmission_encounter_id) AS readmissions_within_30days,
    ROUND(COUNT(DISTINCT r.readmission_encounter_id) * 100.0 / 
          COUNT(DISTINCT id.initial_encounter_id), 2) AS readmission_rate_percent
FROM inpatient_discharges id
LEFT JOIN readmissions r 
    ON id.initial_encounter_id = r.initial_encounter_id
INNER JOIN specialties s ON id.specialty_id = s.specialty_id
GROUP BY s.specialty_name
ORDER BY readmission_rate_percent DESC;

Schema Analysis:
- Tables joined: 3 (encounters self-joined + providers + specialties)
- Number of joins: Self-join on encounters + 2 additional joins

Performance (13.2k Rows):
- Execution time: 0.093 seconds (93 milliseconds) 
- Estimated rows scanned: ~13,233 rows
- Actual rows processed: 13,200 rows scanned, filtered to 4,533 inpatient discharges

Bottleneck Identified:
- Full table scan on encounters: 13,200 rows scanned.
- Self-join loop explosion: Each of the 4,533 initial discharges triggers nesting.
- Complex predicates: Filtering and DATEDIFF happen inside the loop.
- Scaling Issue: 70% increase in latency; self-joins degrade exponentially.

==========================================

QUESTION 4: Revenue by Specialty & Month
-----------------------------------------

SQL Query:
SELECT 
    DATE_FORMAT(e.encounter_date, '%Y-%m') AS revenue_month,
    s.specialty_name,
    COUNT(DISTINCT e.encounter_id) AS total_encounters,
    SUM(b.allowed_amount) AS total_revenue,
    ROUND(AVG(b.allowed_amount), 2) AS avg_revenue_per_encounter
FROM billing b
INNER JOIN encounters e ON b.encounter_id = e.encounter_id
INNER JOIN providers p ON e.provider_id = p.provider_id
INNER JOIN specialties s ON p.specialty_id = s.specialty_id
WHERE b.claim_status = 'Paid'
GROUP BY 
    DATE_FORMAT(e.encounter_date, '%Y-%m'),
    s.specialty_name
ORDER BY 
    revenue_month,
    total_revenue DESC;

Schema Analysis:
- Tables joined: 4 (billing → encounters → providers → specialties)
- Number of joins: 3

Performance (13.2k Rows):
- Execution time: 0.095 seconds (95 milliseconds) [Previous: 52ms]
- Estimated rows scanned: 13,200 rows from billing table
- Actual rows processed: ~9,240 rows after filtering

Bottleneck Identified:
- Table scan on billing: Full scan of 13,200 rows.
- Multiple sorts: Sorting ~9,240 rows before grouping.
- JOIN chain overhead: 9,240 rows requiring 3 joins each.
- Scaling Issue: Latency nearly doubled due to linear scan/sort costs.

==========================================

SUMMARY OF FINDINGS (STRESS TEST):
- **Fragility**: Small data increases (30%) caused disproportionate latency spikes (up to 200%).
- **Self-Joins**: The Readmission query (Q3) is the most vulnerable to growth ($O(N^2)$ behavior).
- **Sort Overhead**: Queries relying on `Using filesort` (Q1, Q4) slowed down significantly as memory buffers filled.
- **OLAP Justification**: The "Stress Test" proves that the Normalized schema cannot support historical growth. The Star Schema is required not just for speed, but for scalability.
