HEALTHCARE ANALYTICS LAB - QUERY ANALYSIS
OLTP Schema Performance Evaluation
==========================================

QUESTION 1: Monthly Encounters by Specialty
--------------------------------------------

SQL Query:
SELECT 
    DATE_FORMAT(e.encounter_date, '%Y-%m') AS encounter_month,
    s.specialty_name,
    e.encounter_type,
    COUNT(DISTINCT e.encounter_id) AS total_encounters,
    COUNT(DISTINCT e.patient_id) AS unique_patients
FROM encounters e
INNER JOIN providers p ON e.provider_id = p.provider_id
INNER JOIN specialties s ON p.specialty_id = s.specialty_id
GROUP BY 
    DATE_FORMAT(e.encounter_date, '%Y-%m'),
    s.specialty_name,
    e.encounter_type
ORDER BY 
    encounter_month,
    s.specialty_name,
    e.encounter_type;

Schema Analysis:
- Tables joined: 3 (encounters → providers → specialties)
- Number of joins: 2

Performance:
- Execution time: 0.0518 seconds (51.8 milliseconds)
- Estimated rows scanned: 9,784 rows
- Actual rows processed: 10,000 rows from encounters table

Bottleneck Identified:
- Full sort operation: 10,000 rows sorted before grouping
- Nested loop joins: 1,000 provider-specialty combinations, each triggering 10 encounter lookups (10,000 total index lookups)
- Date calculation at query time: DATE_FORMAT() computed 10,000 times during GROUP BY
- Multiple DISTINCT counts: Two separate distinct aggregations (encounter_id and patient_id) computed for each group
- No pre-aggregated data: All counts and groupings calculated at query time
- Large intermediate result set: Join produces 10,000 rows before aggregation reduces to 720 final groups

==========================================

QUESTION 2: Top Diagnosis-Procedure Pairs
------------------------------------------

SQL Query:
SELECT 
    d.icd10_code,
    d.icd10_description,
    pr.cpt_code,
    pr.cpt_description,
    COUNT(DISTINCT ed.encounter_id) AS encounter_count
FROM encounter_diagnoses ed
INNER JOIN diagnoses d ON ed.diagnosis_id = d.diagnosis_id
INNER JOIN encounter_procedures ep ON ed.encounter_id = ep.encounter_id
INNER JOIN procedures pr ON ep.procedure_id = pr.procedure_id
GROUP BY 
    d.icd10_code,
    d.icd10_description,
    pr.cpt_code,
    pr.cpt_description
ORDER BY 
    encounter_count DESC;

Schema Analysis:
- Tables joined: 4 (encounter_diagnoses → diagnoses → encounter_procedures → procedures)
- Number of joins: 4

Performance:
- Execution time: 0.104 seconds (104 milliseconds)
- Estimated rows scanned: 9,744 rows
- Actual rows processed: 10,000 rows from diagnoses table

Bottleneck Identified:
- Full table scan on diagnoses: 10,000 rows scanned from diagnoses table
- Cartesian product explosion: Junction table joins create 10,000 intermediate rows
- Multiple nested loops: 4 levels of nested loop joins, with 10,000 iterations each (40,000 total index lookups)
- Double sort operation: Data sorted before grouping (10,000 rows) and after aggregation (592 rows)
- Complex GROUP BY: Grouping by 4 text columns (2 codes + 2 descriptions)
- DISTINCT count overhead: Computing distinct encounter_id across 10,000 rows to deduplicate cartesian product
- No indexed access: Starting with full table scan instead of using indexes on junction tables

==========================================

QUESTION 3: 30-Day Readmission Rate
------------------------------------

SQL Query:
WITH inpatient_discharges AS (
    SELECT 
        e1.patient_id,
        e1.encounter_id AS initial_encounter_id,
        e1.discharge_date,
        e1.provider_id,
        p.specialty_id
    FROM encounters e1
    INNER JOIN providers p ON e1.provider_id = p.provider_id
    WHERE e1.encounter_type = 'Inpatient' 
      AND e1.discharge_date IS NOT NULL
),
readmissions AS (
    SELECT 
        id.patient_id,
        id.initial_encounter_id,
        id.discharge_date,
        id.specialty_id,
        e2.encounter_id AS readmission_encounter_id,
        e2.encounter_date AS readmission_date,
        DATEDIFF(e2.encounter_date, id.discharge_date) AS days_to_readmit
    FROM inpatient_discharges id
    INNER JOIN encounters e2 
        ON id.patient_id = e2.patient_id
        AND e2.encounter_type = 'Inpatient'
        AND e2.encounter_date > id.discharge_date
        AND DATEDIFF(e2.encounter_date, id.discharge_date) <= 30
)
SELECT 
    s.specialty_name,
    COUNT(DISTINCT id.initial_encounter_id) AS total_discharges,
    COUNT(DISTINCT r.readmission_encounter_id) AS readmissions_within_30days,
    ROUND(COUNT(DISTINCT r.readmission_encounter_id) * 100.0 / 
          COUNT(DISTINCT id.initial_encounter_id), 2) AS readmission_rate_percent
FROM inpatient_discharges id
LEFT JOIN readmissions r 
    ON id.initial_encounter_id = r.initial_encounter_id
INNER JOIN specialties s ON id.specialty_id = s.specialty_id
GROUP BY s.specialty_name
ORDER BY readmission_rate_percent DESC;

Schema Analysis:
- Tables joined: 3 (encounters self-joined + providers + specialties)
- Number of joins: Self-join on encounters + 2 additional joins

Performance:
- Execution time: 0.0453 seconds (45.3 milliseconds)
- Estimated rows scanned: 9,784 rows from encounters table
- Actual rows processed: 10,000 rows scanned, filtered to 3,333 inpatient discharges

Bottleneck Identified:
- Full table scan on encounters: 10,000 rows scanned, then filtered to 3,333 inpatient encounters
- Self-join creates nested loops: Each of 3,333 initial discharges triggers lookup for readmissions (3,333 patient_id index lookups)
- Complex join conditions in self-join: Multiple filters applied per iteration (encounter type, date comparison, 30-day window)
- Date calculation overhead: to_days() function called twice for each potential readmission pair
- Multiple DISTINCT counts: Four distinct aggregations computed (2 for initial encounters, 2 for readmissions)
- Sort before and after aggregation: Data sorted by specialty name (3,333 rows), then by readmission rate (20 final rows)
- Low readmission rate multiplies work: Only 264 actual readmissions found (7.9%), but all encounters must be checked
- No pre-computed readmission flags: Must calculate readmission status for every encounter at query time

==========================================

QUESTION 4: Revenue by Specialty & Month
-----------------------------------------

SQL Query:
SELECT 
    DATE_FORMAT(e.encounter_date, '%Y-%m') AS revenue_month,
    s.specialty_name,
    COUNT(DISTINCT e.encounter_id) AS total_encounters,
    SUM(b.allowed_amount) AS total_revenue,
    ROUND(AVG(b.allowed_amount), 2) AS avg_revenue_per_encounter
FROM billing b
INNER JOIN encounters e ON b.encounter_id = e.encounter_id
INNER JOIN providers p ON e.provider_id = p.provider_id
INNER JOIN specialties s ON p.specialty_id = s.specialty_id
WHERE b.claim_status = 'Paid'
GROUP BY 
    DATE_FORMAT(e.encounter_date, '%Y-%m'),
    s.specialty_name
ORDER BY 
    revenue_month,
    total_revenue DESC;

Schema Analysis:
- Tables joined: 4 (billing → encounters → providers → specialties)
- Number of joins: 3

Performance:
- Execution time: 0.0516 seconds (51.6 milliseconds)
- Estimated rows scanned: 10,000 rows from billing table
- Actual rows processed: 7,000 rows after filtering

Bottleneck Identified:
- Table scan on billing: Full table scan of 10,000 rows, then filtered to 7,000 rows
- Multiple sorts: Data sorted twice (once before grouping, once after aggregation)
- JOIN chain overhead: Each of the 7,000 billing records requires 3 index lookups (21,000 total lookups)
- Date calculation at query time: DATE_FORMAT() computed 7,000 times during GROUP BY
- No indexes on claim_status: Filtering happens after full table scan instead of using an index

==========================================

SUMMARY OF FINDINGS:
- All queries suffer from multiple table joins (2-4 joins each)
- Date calculations happen at query time instead of being pre-computed
- No pre-aggregated metrics exist - all calculations done on-the-fly
- Junction tables cause row explosion and require DISTINCT counts
- Self-joins for temporal analysis are particularly expensive
- Average execution time: 63.2 milliseconds across all queries